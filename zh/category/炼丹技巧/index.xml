<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>炼丹技巧 | 大道之行</title>
    <link>http://resume.2oil.top/zh/category/%E7%82%BC%E4%B8%B9%E6%8A%80%E5%B7%A7/</link>
      <atom:link href="http://resume.2oil.top/zh/category/%E7%82%BC%E4%B8%B9%E6%8A%80%E5%B7%A7/index.xml" rel="self" type="application/rss+xml" />
    <description>炼丹技巧</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh-Hans</language><copyright>© 2021-2023 深度学习两滴油 版权所有. 鲁ICP备2021007223号-1 鲁公网安备37132702371387号
  </copyright><lastBuildDate>Wed, 29 Jun 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://resume.2oil.top/media/icon_hud0ce531716296da633c567fb13fa2911_442_512x512_fill_lanczos_center_2.png</url>
      <title>炼丹技巧</title>
      <link>http://resume.2oil.top/zh/category/%E7%82%BC%E4%B8%B9%E6%8A%80%E5%B7%A7/</link>
    </image>
    
    <item>
      <title>炼丹技巧-对抗训练</title>
      <link>http://resume.2oil.top/zh/post/2022-06-29/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      <guid>http://resume.2oil.top/zh/post/2022-06-29/</guid>
      <description>&lt;h3 id=&#34;fgm&#34;&gt;FGM&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;class FGM:
    &amp;quot;&amp;quot;&amp;quot;
    参考自: https://blog.csdn.net/qq_40176087/article/details/121512229
    FGSM的更新公式为: eplison * torch.sign(param.grad)
    &amp;quot;&amp;quot;&amp;quot;

    def __init__(self, model, eps=1.) -&amp;gt; None:
        self.model = model
        self.eps = eps
        self.backup = {}

    # only attack word embedding
    def attack(self, embedding_name=&amp;quot;word_embeddings&amp;quot;):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                self.backup[name] = param.data.clone()
                norm = torch.norm(param.grad)
                if norm and not torch.isnan(norm):
                    r_at = self.eps * param.grad / norm
                    param.data.add_(r_at)

    def restore(self, embedding_name=&amp;quot;word_embeddings&amp;quot;):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;fgsm&#34;&gt;FGSM&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;class FGSM:
    &amp;quot;&amp;quot;&amp;quot;
    参考自: https://blog.csdn.net/qq_40176087/article/details/121512229
    FGSM的更新公式为: eplison * torch.sign(param.grad)
    &amp;quot;&amp;quot;&amp;quot;

    def __init__(self, model, eps=1.) -&amp;gt; None:
        self.model = model
        self.eps = eps
        self.backup = {}

    # only attack word embedding
    def attack(self, embedding_name=&amp;quot;word_embeddings&amp;quot;):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                self.backup[name] = param.data.clone()
                norm = torch.norm(param.grad)
                if norm and not torch.isnan(norm):
                    r_at = self.eps * torch.sign(param.grad)
                    param.data.add_(r_at)

    def restore(self, embedding_name=&amp;quot;word_embeddings&amp;quot;):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;pgd&#34;&gt;PGD&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;class PGD:

    def __init__(self, model, eps=1., alpha=0.3) -&amp;gt; None:
        self.model = model
        self.eps = eps
        self.alpha = alpha
        self.emb_backup = {}
        self.grad_backup = {}

    def attack(self, embedding_name=&amp;quot;word_embeddings&amp;quot;, is_first_attack=False):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                if is_first_attack:
                    self.emb_backup[name] = param.data.clone()
                norm = torch.norm(param.grad)
                if norm != 0 and not torch.isnan(norm):
                    r_at = self.alpha * param.data / norm
                    param.data.add_(r_at)
                    param.data = self.project(name, param.data)

    def restore(self, embedding_name=&amp;quot;word_embeddings&amp;quot;):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                assert name in self.emb_backup
                param.data = self.emb_backup[name]
        self.emb_backup = {}

    def project(self, param_name, param_data):
        r = param_data - self.emb_backup[param_name]
        if torch.norm(r) &amp;gt; self.eps:
            r = self.eps * r / torch.norm(r)
        return self.emb_backup[param_name] + r

    def backup_grad(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and param.grad is not None:
                self.grad_backup[name] = param.grad.clone()

    def restore_grad(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and param.grad is not None:
                param.grad = self.grad_backup[name]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;实验效果&#34;&gt;实验效果&lt;/h3&gt;
&lt;p&gt;在微博情绪识别任务[2]中，有微弱提升。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;method&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;performance&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;without adv&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;96.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;with fgm&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;97.12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\Delta$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;with fgsm&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;训练失败，验证集准确率下降到52，考虑梯度问题&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;参考文献&#34;&gt;参考文献&lt;/h3&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://blog.csdn.net/qq_40176087/article/details/121512229&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;对抗训练fgm、fgsm和pgd原理和源码分析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://challenge.xfyun.cn/topic/info?type=epidemic-weibo&amp;amp;option=tjjg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;疫情微博情绪识别挑战赛&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>炼丹技巧-EMA（指数移动平均）</title>
      <link>http://resume.2oil.top/zh/post/2022-06-27/</link>
      <pubDate>Mon, 27 Jun 2022 00:00:00 +0000</pubDate>
      <guid>http://resume.2oil.top/zh/post/2022-06-27/</guid>
      <description>&lt;h3 id=&#34;原理&#34;&gt;原理&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;来自于参考文献[1]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;基本假设：模型权重在最后的$n$步内，会在实际的最优点处抖动，因此取最后$n$步的平均，能使模型更加鲁棒。&lt;/p&gt;
&lt;p&gt;权重参数更新公式：$v_{t} = \beta * v_{t-1} + (1 - \beta) * v_{t}$&lt;/p&gt;
&lt;h3 id=&#34;代码&#34;&gt;代码&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;来自于参考文献[1]，注意只在验证和测试时使用ema的平均参数，训练时不用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;class EMA:
    def __init__(self, model, decay):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}

    def register(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.shadow[name] = param.data.clone()
    
    def update(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]
                self.shadow[name] = new_average.clone()

    def apply_shadow(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                self.backup[name] = param.data
                param.data = self.shadow[name]
    
    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;实验效果&#34;&gt;实验效果&lt;/h3&gt;
&lt;p&gt;在微博情绪识别任务[2]中，有微弱提升。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;method&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;performance&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;without ema&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;96.83&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;with ema&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;96.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\Delta$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.16&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;参考文献&#34;&gt;参考文献&lt;/h3&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://zhuanlan.zhihu.com/p/68748778&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;【炼丹技巧】指数移动平均（EMA）的原理及PyTorch实现&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://challenge.xfyun.cn/topic/info?type=epidemic-weibo&amp;amp;option=tjjg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;疫情微博情绪识别挑战赛&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
