<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FGM | Never-Ending Travel</title>
    <link>http://resume.2oil.top/tag/fgm/</link>
      <atom:link href="http://resume.2oil.top/tag/fgm/index.xml" rel="self" type="application/rss+xml" />
    <description>FGM</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2021-2023. Never-Ending Travel. All Rights Reserved. [鲁ICP备2021007223号-1](https://beian.miit.gov.cn/)</copyright><lastBuildDate>Wed, 29 Jun 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://resume.2oil.top/media/icon_hud0ce531716296da633c567fb13fa2911_442_512x512_fill_lanczos_center_2.png</url>
      <title>FGM</title>
      <link>http://resume.2oil.top/tag/fgm/</link>
    </image>
    
    <item>
      <title>炼丹技巧-对抗训练</title>
      <link>http://resume.2oil.top/post/2022-06-29/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      <guid>http://resume.2oil.top/post/2022-06-29/</guid>
      <description>&lt;h3 id=&#34;fgm&#34;&gt;FGM&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;class FGM:
    &amp;quot;&amp;quot;&amp;quot;
    参考自: https://blog.csdn.net/qq_40176087/article/details/121512229
    FGSM的更新公式为: eplison * torch.sign(param.grad)
    &amp;quot;&amp;quot;&amp;quot;

    def __init__(self, model, eps=1.) -&amp;gt; None:
        self.model = model
        self.eps = eps
        self.backup = {}

    # only attack word embedding
    def attack(self, embedding_name=&amp;quot;word_embeddings&amp;quot;):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                self.backup[name] = param.data.clone()
                norm = torch.norm(param.grad)
                if norm and not torch.isnan(norm):
                    r_at = self.eps * param.grad / norm
                    param.data.add_(r_at)

    def restore(self, embedding_name=&amp;quot;word_embeddings&amp;quot;):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;fgsm&#34;&gt;FGSM&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;class FGSM:
    &amp;quot;&amp;quot;&amp;quot;
    参考自: https://blog.csdn.net/qq_40176087/article/details/121512229
    FGSM的更新公式为: eplison * torch.sign(param.grad)
    &amp;quot;&amp;quot;&amp;quot;

    def __init__(self, model, eps=1.) -&amp;gt; None:
        self.model = model
        self.eps = eps
        self.backup = {}

    # only attack word embedding
    def attack(self, embedding_name=&amp;quot;word_embeddings&amp;quot;):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                self.backup[name] = param.data.clone()
                norm = torch.norm(param.grad)
                if norm and not torch.isnan(norm):
                    r_at = self.eps * torch.sign(param.grad)
                    param.data.add_(r_at)

    def restore(self, embedding_name=&amp;quot;word_embeddings&amp;quot;):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;pgd&#34;&gt;PGD&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;class PGD:

    def __init__(self, model, eps=1., alpha=0.3) -&amp;gt; None:
        self.model = model
        self.eps = eps
        self.alpha = alpha
        self.emb_backup = {}
        self.grad_backup = {}

    def attack(self, embedding_name=&amp;quot;word_embeddings&amp;quot;, is_first_attack=False):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                if is_first_attack:
                    self.emb_backup[name] = param.data.clone()
                norm = torch.norm(param.grad)
                if norm != 0 and not torch.isnan(norm):
                    r_at = self.alpha * param.data / norm
                    param.data.add_(r_at)
                    param.data = self.project(name, param.data)

    def restore(self, embedding_name=&amp;quot;word_embeddings&amp;quot;):
        for name, param in self.model.named_parameters():
            if param.requires_grad and embedding_name in name:
                assert name in self.emb_backup
                param.data = self.emb_backup[name]
        self.emb_backup = {}

    def project(self, param_name, param_data):
        r = param_data - self.emb_backup[param_name]
        if torch.norm(r) &amp;gt; self.eps:
            r = self.eps * r / torch.norm(r)
        return self.emb_backup[param_name] + r

    def backup_grad(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and param.grad is not None:
                self.grad_backup[name] = param.grad.clone()

    def restore_grad(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and param.grad is not None:
                param.grad = self.grad_backup[name]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;实验效果&#34;&gt;实验效果&lt;/h3&gt;
&lt;p&gt;在微博情绪识别任务[2]中，有微弱提升。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;method&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;performance&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;without adv&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;96.99&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;with fgm&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;97.12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;$\Delta$&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;code&gt;with fgsm&lt;/code&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;训练失败，验证集准确率下降到52，考虑梯度问题&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;参考文献&#34;&gt;参考文献&lt;/h3&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://blog.csdn.net/qq_40176087/article/details/121512229&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;对抗训练fgm、fgsm和pgd原理和源码分析&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://challenge.xfyun.cn/topic/info?type=epidemic-weibo&amp;amp;option=tjjg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;疫情微博情绪识别挑战赛&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
